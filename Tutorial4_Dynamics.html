
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Nengo Neurons: Dynamics &#8212; ECE495 Intro to Neuromorhic Engineering</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Tutorial4_Dynamics';</script>
    <link rel="icon" href="_static/favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Algorithms in Nengo: Path Planning" href="Tutorial6_PathPlanning.html" />
    <link rel="prev" title="Nengo Neurons: Transformation" href="Tutorial3b_NeuronBasics.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="ECE495 Intro to Neuromorhic Engineering - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="ECE495 Intro to Neuromorhic Engineering - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Intro to Neuromorphic Engineering
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Setup</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="venv_setup.html">ECE 495 Setup Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="495setup_LastName.html">Lab 0: Virtual Environment Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">In-class Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Tutorial3a_NeuronBasics.html">Nengo Neurons: Representation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tutorial3b_NeuronBasics.html">Nengo Neurons: Transformation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Nengo Neurons: Dynamics</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tutorial6_PathPlanning.html">Algorithms in Nengo: Path Planning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Tutorial7_SpikingData.html">Algorithms in Nengo: Spiking data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lab Assignments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Lab1_DNN_LastName.html">Lab 1: Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lab2_SNN_LastName.html">Lab 2: Spiking Neural Networks using NengoDL</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lab3_NeuronBasics_LastName.html">Lab 3: Neuron Basics using Nengo</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lab4_Dynamics_LastName.html">Lab 4: Navigation Dynamics using Nengo</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lab5_BubbleSort_LastName.html">Lab 5: Bubble Sort using Nengo Neurons</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lab6_PathPlanning_LastName.html">Lab 6: Krichmar Path Planning using Nengo Neurons</a></li>
<li class="toctree-l1"><a class="reference internal" href="Lab7_SpikingData_LastName.html">Lab7: Spiking data processed by Nengo Neurons</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/kaitlin-fair/ECE495_Fa24/blob/main/book/Tutorial4_Dynamics.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/kaitlin-fair/ECE495_Fa24" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/kaitlin-fair/ECE495_Fa24/issues/new?title=Issue%20on%20page%20%2FTutorial4_Dynamics.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Tutorial4_Dynamics.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Nengo Neurons: Dynamics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#set-up">Set up</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bad-recurrence-using-neurons">Bad Recurrence using Neurons</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrence-in-nengo">Recurrence in Nengo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#okay-but-why">Okay, but WHY?!</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-feedback">Why feedback?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#let-s-actually-do-that-now">Let’s actually do that now!</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#functions-versus-transforms">Functions versus Transforms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integrator">Integrator</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#probe-it-and-run-it">Probe it and Run it</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-it">Plot it</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-memory">Working Memory</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Probe it and Run it</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Plot it</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-oscillator-on-your-own-for-an-additional-example">Simple Oscillator - On your own for an additional example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resources">Resources</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="nengo-neurons-dynamics">
<h1>Nengo Neurons: Dynamics<a class="headerlink" href="#nengo-neurons-dynamics" title="Link to this heading">#</a></h1>
<p>In this demonstration we will:</p>
<ol class="arabic simple">
<li><p>Understand and implement recurrence in a Nengo network</p></li>
<li><p>Create an integrator with neurons</p></li>
<li><p>Create an oscillator with neurons</p></li>
</ol>
<section id="set-up">
<h2>Set up<a class="headerlink" href="#set-up" title="Link to this heading">#</a></h2>
<p><strong>Ensure you are using your 495 Virtual Environment before you begin!</strong></p>
<p>Import Nengo and other supporting libraries into your program to get started:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">nengo</span>
<span class="kn">from</span> <span class="nn">nengo.processes</span> <span class="kn">import</span> <span class="n">Piecewise</span>
<span class="kn">from</span> <span class="nn">nengo.processes</span> <span class="kn">import</span> <span class="n">WhiteSignal</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="bad-recurrence-using-neurons">
<h2>Bad Recurrence using Neurons<a class="headerlink" href="#bad-recurrence-using-neurons" title="Link to this heading">#</a></h2>
<p>Recurrence in neural networks can be used to implement stable dynamics (think controls systems). Such dynamics are important for memory, noise cleanup, statistical inference, and many other dynamic transformations. Recurrent neurons can also be used if you will be performing the same computation over and over again within an algorithm (i.e. just build the neuron once and send in different inputs). Another use of recurrent neurons is online learning (edge computing), depending on the algorithm.</p>
<p>Let’s say I have an algorithm that repeatedly needs to compare two values. I don’t want to have to build a comparator for every instance of comparing two values. <strong>Why do you think that is?</strong></p>
<p>Instead, I decide to use the same comparator to do two comparisons in sequence. In this example, I first want to compare values .1 to .25, then i want to take the max value of those two and compare to .5, in which case the output should converge to… <strong>what??</strong></p>
<p>Let’s see what happens.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;BasicRecurrence&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compare</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># Try these as our inputs first</span>
    <span class="n">compareInp1</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">([</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.25</span><span class="p">])</span>
    <span class="n">compareInp2</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">([</span><span class="mf">.5</span><span class="p">])</span>

    <span class="c1"># Try these as our inputs second</span>
    <span class="c1">#compareInp1 = []</span>
    <span class="c1">#compareInp1.append(nengo.Node(Piecewise({0: .1, .5: 0})))</span>
    <span class="c1">#compareInp1.append(nengo.Node(Piecewise({0: .3, .5: 0})))</span>
    <span class="c1">#compareInp2 = nengo.Node(Piecewise({1: .5, 1.5: 0}))</span>
    
    <span class="n">combineNeuron</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">dimensions</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">compareNeuron</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">dimensions</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">compareInp1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">combineNeuron</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">compareInp1</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">combineNeuron</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">combineNeuron</span><span class="p">,</span> <span class="n">compareNeuron</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">compare</span><span class="p">)</span>

    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">compareInp2</span><span class="p">,</span> <span class="n">combineNeuron</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">compareNeuron</span><span class="p">,</span> <span class="n">combineNeuron</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">inp1_probe</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">inp1_probe</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">compareInp1</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">inp1_probe</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">compareInp1</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">inp2_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">compareInp2</span><span class="p">)</span>
    <span class="n">out_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">compareNeuron</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="mf">.01</span><span class="p">)</span>

<span class="c1"># Create our simulator</span>
<span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="c1"># Run it for 6 seconds</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Plot the decoded output of the ensemble</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">inp1_probe</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">inp1_probe</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;First two values to be compared&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">inp2_probe</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Second value to be compared to max of first two&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">out_probe</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Output comparisons&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="discussion">
<h3>Discussion<a class="headerlink" href="#discussion" title="Link to this heading">#</a></h3>
<p>When we sent in our constant inputs we immediately recieved feedback in the form of another constant - which was essentially sending two inputs at once into the same neuron ensemble and therefore saturating the neuron (aka radius = 1, max out at about 1). We then made our input piecewise to attempt one comparison at a time, but we still saturated – is there ever a piecewise that could prevent saturation?? Once we were saturated, even comparing to zero still held the max at 1, and therefore our max value was always the saturated value of 1.</p>
<p>Due to the inherent dynamics of Nengo neurons, while the compare neuron ensemble is computing the comparison of two values, the neurons are never comparing the values we actually intend for them to compare because they are being flooded by the recurrence!</p>
</section>
</section>
<section id="recurrence-in-nengo">
<h2>Recurrence in Nengo<a class="headerlink" href="#recurrence-in-nengo" title="Link to this heading">#</a></h2>
<p>Okay, so how do we ensure our neurons do not saturate <em>or</em> actually perform the computations on the values we want when we are using recurrence? Well, we need new functions (that we will call <span class="math notranslate nohighlight">\(f^{\prime}\)</span> and <span class="math notranslate nohighlight">\(g^{\prime}\)</span>) that convert the inherent Nengo neuron dynamics to our <em>desired</em> dynamics.</p>
<p>We have discussed how to compute the neuron representation of a signal in depth (i.e. decode the spikes). As it turns out, this is something we do/did in ECE 346.</p>
<p>Imagine this is a block diagram:<br />
<span class="math notranslate nohighlight">\(u(t)\)</span> –&gt; [<span class="math notranslate nohighlight">\(h(t)\)</span>] –&gt; <span class="math notranslate nohighlight">\(x(t)\)</span></p>
<p>Where <span class="math notranslate nohighlight">\(u(t)\)</span> is our input, <span class="math notranslate nohighlight">\(h(t)\)</span> is our transfer function, and <span class="math notranslate nohighlight">\(x(t)\)</span> is the transformed input (or state of the system). Here, math tells us that <span class="math notranslate nohighlight">\(x(t)=u(t)*h(t)\)</span> where <span class="math notranslate nohighlight">\(u(t)\)</span> is our output spikes, <span class="math notranslate nohighlight">\(h(t)\)</span> is our neuron action potential, and <span class="math notranslate nohighlight">\(x(t)\)</span> is our decoded signal. <em>This is how we (and Nengo) have decoded our spikes!</em></p>
<p>In the case where we are considering <span class="math notranslate nohighlight">\(u(t)\)</span> to be spikes, convolution is not terribly difficult - we’ve been doing it for two weeks! However, if we begin to think of our outputs as an input signal (at the algorithm level), convolution gets complicated. Therefore, we want to use…. <em>Laplace Transforms</em>.</p>
<div class="math notranslate nohighlight">
\[\mathscr{L}\{x(t)\} = X(s)= U(s)H(s)\]</div>
<p>This is now just multiplication!</p>
<p>Fun fact: if the membrane action potential is approximated as <span class="math notranslate nohighlight">\(h(t)=e^{-t/\tau}\)</span> - which is how Nengo approximates it - the Laplace is:</p>
<div class="math notranslate nohighlight">
\[\mathscr{L}\{h(t)\}=\frac{1}{1+s\tau}\]</div>
<p>If we plug <span class="math notranslate nohighlight">\(H(s)\)</span> into <span class="math notranslate nohighlight">\(X(s)=U(s)H(s)\)</span> and rearrange a bit, we get the following:</p>
<div class="math notranslate nohighlight">
\[sX(s) = \frac{1}{\tau}(U(s)-X(s))\]</div>
<p>The Inverse Laplace of <span class="math notranslate nohighlight">\(sX(s)\)</span> is <span class="math notranslate nohighlight">\(\dot{x}\)</span>, which we can use to describe the dynamics of our system (i.e. how much we’ve changed over time)!</p>
<div class="math notranslate nohighlight">
\[\dot{x(t)}=-\frac{1}{\tau}(x(t))-u(t))\]</div>
<p>This is a lot of math, but this is simply what we did in our Jupyter Notebook on Neuron Representation. <span class="math notranslate nohighlight">\(\tau\)</span> is the rate at which we change and <span class="math notranslate nohighlight">\(x(t)-u(t)\)</span> is the total change in our system over time (output-input). You can go back to our very first example and see how <span class="math notranslate nohighlight">\(\tau\)</span> impacts the rate at which we change over time as we move toward the value we intend to represent.</p>
<section id="okay-but-why">
<h3>Okay, but WHY?!<a class="headerlink" href="#okay-but-why" title="Link to this heading">#</a></h3>
<p>This lays the foundation for implementing recurrence using neurons. AND it again shows you that you should really pay attention in math classes.</p>
<p>Now, we are going to feedback our output state x(t) to our input <em>without</em> saturating our neuron using functions <span class="math notranslate nohighlight">\(f^{\prime}\)</span> and <span class="math notranslate nohighlight">\(g^{\prime}\)</span> at the connections. It will take a little more Laplace math to get there.</p>
</section>
<section id="why-feedback">
<h3>Why feedback?<a class="headerlink" href="#why-feedback" title="Link to this heading">#</a></h3>
<p>This all sounds hard, why would we actually want to do this?? Recurrent neurons can be used to implement stable dynamics. Recall our synapse values - when they’re larger, the neurons more accurately represent our signal but it takes a while to get there. Smaller is noiser but faster. However, biological systems only offer synpatic time constants of about 2-200ms. If we decide to stay true to biological systems when we model our algorithms (totally your call), recurrence can enable larger <span class="math notranslate nohighlight">\(\tau\)</span> for the network itself. This means that if our neuron synapses are .005s in our neuron ensemble, we can feed the output of our neuron back to itself with a particular set of dynamics such that the network itself responds at a synaptic time constant of .5 instead! Let’s see how this works. In order to do so, we must math…</p>
<p>Now, our block diagram has a feedback from <span class="math notranslate nohighlight">\(x(t)\)</span> back to the input line, with a function of <span class="math notranslate nohighlight">\(f(x(t))\)</span> attached to the feedback line. If we ignore any external input <span class="math notranslate nohighlight">\(u(t)\)</span> and assess the dynamics alone, we get the same thing as last time, except now we have <span class="math notranslate nohighlight">\(f(x(t))\)</span> instead of <span class="math notranslate nohighlight">\(u(t)\)</span> (because <span class="math notranslate nohighlight">\(f(x(t))\)</span> is now the input if there’s not external input <span class="math notranslate nohighlight">\(u(t)\)</span>).</p>
<div class="math notranslate nohighlight">
\[\dot{x}(t)=-\frac{1}{\tau}(x(t))-f(x(t)))\]</div>
<p>But we know we will have an external input! We will call our external input <span class="math notranslate nohighlight">\(g(u(t))\)</span>. So now, we simply add <span class="math notranslate nohighlight">\(g(u(t))+f(x(t))\)</span> and call that our input, which updates our <span class="math notranslate nohighlight">\(\dot{x}(t)\)</span> to:</p>
<div class="math notranslate nohighlight">
\[\dot{x}(t)=-\frac{1}{\tau}(x(t))-g(u(t))-f(x(t)))=\frac{1}{\tau}(f(x(t)+g(u(t)))-x(t))\]</div>
<p>Here’s the deal about controls - it’s heavily studied and instead of trying to see what we get, we can instead say what we want to get and go from there. For simplicity of notation, we will drop all <span class="math notranslate nohighlight">\(t\)</span> s.</p>
<p>We choose</p>
<div class="math notranslate nohighlight">
\[\dot{x}=f(x)+g(u)\]</div>
<p>meaning our state is simply the feedback of <span class="math notranslate nohighlight">\(f(x)\)</span> added to our input <span class="math notranslate nohighlight">\(g(u)\)</span>. In this case, we want our output to be the representation of our input, just getting there more gradually than the neurons themselves would get us there (i.e. slower but accurate). Therefore, we create a new function that will get us to <span class="math notranslate nohighlight">\(\dot{x}(t)=f(x)+g(u)= \frac{1}{\tau}(f(x(t)+g(u(t)))-x(t))\)</span>, and that is:</p>
<div class="math notranslate nohighlight">
\[f^{\prime}+g^{\prime}=\tau (f(x) + g(u) +x)\]</div>
<p>And we replace <span class="math notranslate nohighlight">\(f(x)+g(u)\)</span> with <span class="math notranslate nohighlight">\(f^{\prime}(u)+g^{\prime}(u)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\dot{x}(t)=\frac{1}{\tau}([\tau (f(x) + g(u) +x)]-x))=f(x)+g(u)\]</div>
<p>Recall, we want <span class="math notranslate nohighlight">\(\dot{x}=f(x)+g(u)\)</span> and we got there! Now we just need a <span class="math notranslate nohighlight">\(f^{\prime}\)</span> and a <span class="math notranslate nohighlight">\(g^{\prime}\)</span> to make that happen. These two functions achieve the dynamics we are looking for:</p>
<div class="math notranslate nohighlight">
\[f^{\prime}(x(t))=\tau f(x(t)) + x(t)\]</div>
<div class="math notranslate nohighlight">
\[g^{\prime}(u)=\tau g(u)\]</div>
<p><strong>These two functions are how we can convert the inherent Nengo neuron dynamics into our desired dynamics of our system.</strong> We will use these functions at our connections in our Nengo model!</p>
</section>
<section id="let-s-actually-do-that-now">
<h3>Let’s actually do that now!<a class="headerlink" href="#let-s-actually-do-that-now" title="Link to this heading">#</a></h3>
<p>Suppose we want the following dynamics in our system (i.e. our entire network):</p>
<div class="math notranslate nohighlight">
\[\dot{x}=-\frac{1}{.05}(x(t)-u(t))\]</div>
<p>This means that we want our network time constant to be <span class="math notranslate nohighlight">\(.05\)</span> regardless of our neuron synaptic time constants. Yes… we could just adjust each neurons time constants, but for one reason or another, maybe that’s not accessible to us.</p>
<p>Instead, we need to implement the dynamics we just derived to make that happen, where <span class="math notranslate nohighlight">\(f(x)=-\frac{x}{.05}\)</span> and <span class="math notranslate nohighlight">\(g(u)=\frac{u}{.05}\)</span>:</p>
<div class="math notranslate nohighlight">
\[f^{\prime}=-\frac{\tau}{.05}x + x\]</div>
<div class="math notranslate nohighlight">
\[g^{\prime}=\frac{\tau}{.05}u\]</div>
<p>These will be the functions used in our Nengo network to achieve the desired dynamics, with <span class="math notranslate nohighlight">\(f^{\prime}\)</span> being the feed forward function and <span class="math notranslate nohighlight">\(g^{\prime}\)</span> being the feedback function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Recurrence&quot;</span><span class="p">)</span>

<span class="n">synaptic_tau</span> <span class="o">=</span> <span class="mf">.005</span> <span class="c1"># actual neuron tau, much smaller, responds quickly but noisily</span>
<span class="n">desired_tau</span> <span class="o">=</span> <span class="mf">.05</span> <span class="c1"># much larger, therefore more stable for network as a whole</span>

<span class="c1"># f&#39; and g&#39;</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">synaptic_tau</span><span class="o">/</span><span class="n">desired_tau</span><span class="p">)</span><span class="o">*</span><span class="n">u</span>

<span class="k">def</span> <span class="nf">recurrent</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">synaptic_tau</span><span class="o">/</span><span class="n">desired_tau</span><span class="p">)</span><span class="o">*</span><span class="n">x</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">dimensions</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">stim</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">Piecewise</span><span class="p">({</span><span class="mi">0</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">1</span><span class="p">}))</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">stim</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>

    <span class="n">b</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">dimensions</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">forward</span><span class="p">)</span>

    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">recurrent</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Probe it, run it, plot it</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">a_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">synaptic_tau</span><span class="p">)</span>
    <span class="n">b_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">synaptic_tau</span><span class="p">)</span>

<span class="c1"># Create our simulator</span>
<span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="c1"># Run it for 6 seconds</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Plot the decoded output of the ensemble</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">a_probe</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Synpatic tau&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">b_probe</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Network (desired) tau&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id1">
<h3>Discussion<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>In the plots, you can see that the neurons themselves have a shorter time constant than that of the network. We can choose any synaptic time constant for your neurons and you’ll get the same results for the network using this dynamical system. <strong>Try it!</strong></p>
<p>That was a whole lot of math to do something pretty simple in Nengo. BUT I wanted you to understand how the functions were determined. Ultimately, whatever dynamics we want our system to have can be achieved using a feedback of some sort with the right associated functions.</p>
<p>Let’s keep going with two more examples.</p>
</section>
</section>
<section id="functions-versus-transforms">
<h2>Functions versus Transforms<a class="headerlink" href="#functions-versus-transforms" title="Link to this heading">#</a></h2>
<p>Before we hit the next example, let’s discuss how we’ve been implementing functions using neurons so far. We typically call an argument called <code class="docutils literal notranslate"><span class="pre">function</span></code> at our Nengo connection, which is exactly what we just did:</p>
<p><code class="docutils literal notranslate"><span class="pre">def</span> <span class="pre">forward(u):</span></code><br />
<code class="docutils literal notranslate"><span class="pre">return</span> <span class="pre">(synaptic_tau/desired_tau)*u</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">model:</span></code><br />
<code class="docutils literal notranslate"><span class="pre">nengo.Connection(a,</span> <span class="pre">b,</span> <span class="pre">function=forward)</span></code></p>
<p>Because this is a <strong>linear transformation</strong> (i.e. we scale the input value by a constant), we could save ourselves a few lines of codee and instead use something called a <code class="docutils literal notranslate"><span class="pre">transform</span></code> to acheive the same exact thing:</p>
<p><code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">model:</span></code><br />
<code class="docutils literal notranslate"><span class="pre">nengo.Connection(a,</span> <span class="pre">b,</span> <span class="pre">transform=synaptic_tau/desired_tau)</span></code></p>
<p>Both functions multiply the input to Nengo ensemble <code class="docutils literal notranslate"><span class="pre">b</span></code> by <code class="docutils literal notranslate"><span class="pre">synaptic_tau/desired_tau</span></code>, they just do so with different input arguments at the connection. Going forward, for linear transformations we will typically use the <code class="docutils literal notranslate"><span class="pre">transform</span></code> argument. For more complicated transformations, we will still define functions – because how would you actually square something with a linear transform??</p>
</section>
<section id="integrator">
<h2>Integrator<a class="headerlink" href="#integrator" title="Link to this heading">#</a></h2>
<p>This is a simple example of a recurrent network to create an integrator, which essentially builds memory with neurons. Integrators are biologically plausible. In fact, we have neurons that perform this function to convert velocity signals (horizontal and vertical movements) into eye position commands (where you want your eye to go based on velocity). The interesting thing about integrators is that the neuron output remains the same even if the input is 0 and only moves again if the input becomes non-zero (i.e. once your eye goes to the top-left, it doesn’t drift back to center until you decide it should). Now, think through this in terms of feedback to decide if this is intuitive to you. We will then be able to see this in our output plots.</p>
<p>In terms of dynamics, we start with this linear dynamical system:</p>
<div class="math notranslate nohighlight">
\[\dot{x}=f(x)+g(u)=Ax+Bu \]</div>
<p>where <span class="math notranslate nohighlight">\(x\)</span> is again our output state, <span class="math notranslate nohighlight">\(u\)</span> is our input, and <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> determine the direction/strenght of <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(u\)</span> contributions. We only want our outputs to change as a result of our input and we want to remember our prior input when the current input is 0. Therefore, A=0 and B=I. This tells us that at every point in time, the change to our state is the input as expected per our above definition of an integrator.</p>
<p>We must define functions for our feed forward and feedback aspects of our recurring network:</p>
<div class="math notranslate nohighlight">
\[f^{\prime}(x)= \tau f(x) + x = \tau Ax + x = x\]</div>
<div class="math notranslate nohighlight">
\[g^{\prime}(u)=\tau g(u)  =\tau Bu = \tau Iu =\tau u\]</div>
<p>For this example, our input is a piecewise function so you can see that the output is integrating (i.e. summing over time) the input. Note that since the integrator constantly sums its input, it will saturate quickly if you leave the input non-zero. This makes it clear that neurons have a finite range of representation. Such saturation effects however can be exploited to perform useful computations (e.g. soft normalization).</p>
<p>You’ll notice we call an argument <code class="docutils literal notranslate"><span class="pre">transform</span></code> instead of <code class="docutils literal notranslate"><span class="pre">function</span></code> in our connections. Because we simply multiply <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(u\)</span> by 1 and <span class="math notranslate nohighlight">\(\tau\)</span> respectively (a linear transformation), we can use the <code class="docutils literal notranslate"><span class="pre">transform</span></code> argument, which may be simpler than spending time defining a function. However, for cases in which your function is more complicated (such as implementing a reLU - i.e. a nonlinear transformation), the <code class="docutils literal notranslate"><span class="pre">function</span></code> argument will be the way to go. Read more about this <a class="reference external" href="https://www.nengo.ai/nengo/connections.html">here</a>. If this isn’t intuitive to you, feel free to instead define functions. You can always define a function and use <code class="docutils literal notranslate"><span class="pre">function</span></code> for your connections; however, note that there are cases (non-linear transformations / more complicated functions) in which <code class="docutils literal notranslate"><span class="pre">transform</span></code> will not work.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Integrator&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># create the recurrent neuron ensemble</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">dimensions</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># create piecewise input</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">Piecewise</span><span class="p">({</span><span class="mi">0</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="mi">0</span><span class="p">}))</span>

    <span class="c1"># Using a long time constant for stability (less noise)</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="mf">0.1</span> 
    
    <span class="c1"># if you wanted to define functions, they might look like this</span>
    <span class="c1">#def forward(u):</span>
    <span class="c1">#    return tau*u</span>
    <span class="c1">#def recurrent(x):</span>
    <span class="c1">#    return x</span>

    <span class="c1"># Connect the population to itself</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span>  
    
    <span class="c1"># Connect the input</span>
    <span class="c1"># The same time constant as recurrent to make it more &#39;ideal&#39;</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="p">[[</span><span class="n">tau</span><span class="p">]],</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span>  
</pre></div>
</div>
</div>
</div>
<section id="probe-it-and-run-it">
<h3>Probe it and Run it<a class="headerlink" href="#probe-it-and-run-it" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># Add probes</span>
    <span class="n">input_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">A_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Create our simulator</span>
<span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="c1"># Run it for 6 seconds</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-it">
<h3>Plot it<a class="headerlink" href="#plot-it" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the decoded output of the ensemble</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">input_probe</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Input&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">A_probe</span><span class="p">],</span> <span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Integrator output&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h3>Discussion<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>The graph shows the response to the input by the integrator. Because it is implemented in neurons, it will not be perfect (i.e. there will be drift). Running several times will give a sense of the kinds of drift you might expect. Drift can be reduced by increasing the number of neurons, using a larger time constant (100-200ms work pretty well for feedback), or changing the inputs more rapidly.</p>
<p>Intuition check: this integrator function is <em>not</em> trying to represent the input signal. Instead, you can think of the input signal as a velocity at which you are moving until the input changes or becomes zero. When the input becomes zero, you can see the “memory” at play. Think through this in terms of eye movement, where the input signal is the velocity at which your eye is moving.</p>
</section>
</section>
<section id="working-memory">
<h2>Working Memory<a class="headerlink" href="#working-memory" title="Link to this heading">#</a></h2>
<p>An integrator is certainly biologically plausible and useful; however, what if we want to reset the value that’s being stored to zero (not wait for the position based on velocity to slowly get there AND THEN have to turn off velocity at just the right time step)?</p>
<p>We can do that since we now understand feedback, how to design an integrator, and multiplication (from neuron_transformations). In this case, we have a system with these dynamics:</p>
<div class="math notranslate nohighlight">
\[ \dot{x} = \alpha Ax + Bu \]</div>
<p>where <span class="math notranslate nohighlight">\(\dot{x}\)</span> is our memory, our input is <span class="math notranslate nohighlight">\(u\)</span>, and our control is <span class="math notranslate nohighlight">\(\alpha\)</span>. Our control determines when we store our input state and clear our controlled storage, which is where multiplication comes into play. If you make <span class="math notranslate nohighlight">\(\alpha\)</span> a negative value, it will clear the state gradually back to zero. More negative values for the controller clear it to zero more quickly. The idea here is that instead of feeding back <span class="math notranslate nohighlight">\(x\)</span> like in our integrator, we feedback something like <span class="math notranslate nohighlight">\(-x+x\)</span> to feedback less than x such that we decay back to zero. If <span class="math notranslate nohighlight">\(\alpha\)</span> is instead zero, we implement the integrator itself, where we feedback <span class="math notranslate nohighlight">\(0+x\)</span> just as before.</p>
<p>Notice that the control <span class="math notranslate nohighlight">\(\alpha\)</span> has no impact on the input itself! So if <span class="math notranslate nohighlight">\(u\)</span> is zero and <span class="math notranslate nohighlight">\(\alpha\)</span> is 0, we hold steady at the value. If <span class="math notranslate nohighlight">\(u\)</span> is zero and <span class="math notranslate nohighlight">\(alpha\)</span> is negative, we decay to zero. If <span class="math notranslate nohighlight">\(u\)</span> is nonzero and <span class="math notranslate nohighlight">\(\alpha\)</span> is negative, once <span class="math notranslate nohighlight">\(u\)</span> becomes zero again, the output will decay to zero.</p>
<p>The functions for our feed forward and feedback aspects of our recurring network look similar to those prior, except now we want for our feedback to negate the x if we are in storage mode. Therefore, <span class="math notranslate nohighlight">\(A=I\)</span> and <span class="math notranslate nohighlight">\(\alpha\)</span> is either 0 or negative:</p>
<div class="math notranslate nohighlight">
\[f^{\prime}(x)= \tau f(x) + x = \tau \alpha Ax + x = \tau \alpha Ix + x = \tau \alpha x + x\]</div>
<div class="math notranslate nohighlight">
\[g^{\prime}(u)=\tau g(u)  =\tau Bu = \tau Iu =\tau u\]</div>
<p>Notice that our feedback function is now non-linear! Meaning we need a 2D neuron ensemble to take in both <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Memory&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    
    <span class="c1"># create piecewise input u</span>
    <span class="n">input_u</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">Piecewise</span><span class="p">({</span><span class="mi">0</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="mi">0</span><span class="p">}))</span>

    <span class="c1"># create piecewise input for controller (consists of 0s and negative values)</span>
    <span class="n">input_control</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">Piecewise</span><span class="p">({</span><span class="mi">0</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mf">.25</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="mi">0</span><span class="p">}))</span>    

    <span class="c1"># create the recurrent neuron ensemble that recieves the above two inputs</span>
    <span class="n">memory</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">dimensions</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Using a long time constant for stability (less noise)</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="mf">0.1</span> 
    
    <span class="c1"># if you wanted to define a function for feedforward, it might look like this</span>
    <span class="c1">#def forward(u):</span>
    <span class="c1">#    return tau*u</span>

    <span class="c1"># feedback function - this is nonlinear and harder for neurons to approximate!</span>
    <span class="c1">#  increase neurons to help </span>
    <span class="k">def</span> <span class="nf">recurrent</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
        <span class="n">alpha</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">state</span>
        <span class="k">return</span> <span class="n">tau</span><span class="o">*</span><span class="n">alpha</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">x</span> 

    <span class="c1"># Create the connection for the controller to the memory ensemble</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">input_control</span><span class="p">,</span><span class="n">memory</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="c1"># Connect the input to the memory ensemble - feed forward (this remains the same!)</span>
    <span class="c1"># The same time constant as recurrent to make it more &#39;ideal&#39;</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">input_u</span><span class="p">,</span> <span class="n">memory</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">transform</span><span class="o">=</span><span class="p">[[</span><span class="n">tau</span><span class="p">]],</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span> 

    <span class="c1"># Connect the population to itself - feedback</span>
    <span class="c1">#  we only want this to impact the u value going in! NOT the controller</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">memory</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">function</span><span class="o">=</span><span class="n">recurrent</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span>  
</pre></div>
</div>
</div>
</div>
<section id="id3">
<h3>Probe it and Run it<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># Add probes</span>
    <span class="n">input_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">input_u</span><span class="p">)</span>
    <span class="n">control_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">input_control</span><span class="p">)</span>
    <span class="n">mem_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Create our simulator</span>
<span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="c1"># Run it for 6 seconds</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h3>Plot it<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the decoded output of the ensemble</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">input_probe</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Input&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">control_probe</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Control&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">mem_probe</span><span class="p">][:,</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Memory output&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id5">
<h3>Discussion<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p>The more negative <span class="math notranslate nohighlight">\(\alpha\)</span> is, the faster it decays to zero (you can see this transition within 2-4 seconds). You can also see from 4-5 seconds that if you have non-zero values for both <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(\alpha\)</span>, you won’t have a linear change in position. Recall drift to account for times when both <span class="math notranslate nohighlight">\(u\)</span> and <span class="math notranslate nohighlight">\(\alpha\)</span> are zero (1-2 seconds and 5-6 seconds).</p>
</section>
</section>
<section id="simple-oscillator-on-your-own-for-an-additional-example">
<h2>Simple Oscillator - On your own for an additional example<a class="headerlink" href="#simple-oscillator-on-your-own-for-an-additional-example" title="Link to this heading">#</a></h2>
<p>Have you had to do some physics math regarding a spring on a block that’s sliding on a frictionless surface? Or a pendullum? These are good examples of simple harmonic oscillators, and we can implement these using recurrent neurons! Turns out this is also biologically plausible - think of repetitive or rhythmic movements (walking, chewing, etc) - and neurons have been measured to show this oscillatory behavior for comparable movements in fish.</p>
<p>Let’s work through a spring on a block that slides on a frictionless surface. Here, we have</p>
<div class="math notranslate nohighlight">
\[F=-kx=ma=m\ddot{x}\]</div>
<p>where <span class="math notranslate nohighlight">\(x\)</span> is position, <span class="math notranslate nohighlight">\(F\)</span> is the force applied to the block, <span class="math notranslate nohighlight">\(k\)</span> is our spring constant, <span class="math notranslate nohighlight">\(m\)</span> is our mass of the object, and <span class="math notranslate nohighlight">\(\ddot{x}\)</span> is acceleration of the mass as a result of force. This can be rearranged to a 2nd order ODE:</p>
<div class="math notranslate nohighlight">
\[ \ddot{x}+\frac{k}{m}x=0 \]</div>
<p>This looks different than the other examples we’ve done where <span class="math notranslate nohighlight">\(\dot{x}=f(x)+g(u)=Ax+Bu\)</span>. First, we will assume an unforced oscillator, therefore <span class="math notranslate nohighlight">\(Bu\)</span> goes to 0. We’d now like to rewrite our problem in the form of <span class="math notranslate nohighlight">\(\dot{x}=Ax\)</span>. Let <span class="math notranslate nohighlight">\(\omega=\sqrt{\frac{k}{m}}\)</span>. With some magical math, we can get something that looks like that form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix}
    \dot{x}_0 \\
    \dot{x}_1 
\end{bmatrix} = \begin{bmatrix}
		            0 &amp; \omega \\
		            -\omega &amp; 0  
	            \end{bmatrix} \begin{bmatrix}
                                    x_0 \\
                                    x_1 
                                \end{bmatrix}\end{split}\]</div>
<p>Let’s now take that back to defining our feed forward and feedback functions:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f^{\prime}(x)= \tau f(x) + x = \tau Ax + x = \begin{bmatrix}
		            0 &amp; \tau \omega \\
		            -\tau \omega &amp; 0  
	            \end{bmatrix}\begin{bmatrix}
                                    x_0 \\
                                    x_1 
                                \end{bmatrix}+ \begin{bmatrix}
                                                    x_0 \\
                                                    x_1 
                                                \end{bmatrix}= \begin{bmatrix}
                                                                    \tau \omega x_1 + x_0 \\
                                                                    -\tau \omega x_0 +x_1
                                                                \end{bmatrix}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[g^{\prime}(u)=\tau g(u)  =\tau Bu = 0\]</div>
<p>To implement <span class="math notranslate nohighlight">\(\begin{bmatrix}
                \tau x_1 + x_0 \\
                -\tau x_0 +x_1
            \end{bmatrix}\)</span> in Nengo, we can use the <code class="docutils literal notranslate"><span class="pre">transform</span></code> argument to get the matrix <span class="math notranslate nohighlight">\(\begin{bmatrix}
                                                                                                1 &amp; \tau \omega \\
                                                                                                -\tau\omega &amp; 1
                                                                                            \end{bmatrix}\)</span>.</p>
<p>We will provide a brief input signal to trigger the oscillatory behavior of the neural representation as the two dimensions interact (i.e. <span class="math notranslate nohighlight">\(x[0]=1\)</span> for .1 seconds, otherwise everything is 0).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the model object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Network</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Oscillator&quot;</span><span class="p">)</span>

<span class="n">tau</span> <span class="o">=</span> <span class="mf">.1</span>
<span class="n">omega</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># Create the ensemble for the oscillator</span>
    <span class="n">neurons</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="n">dimensions</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Create an input signal</span>
    <span class="c1"># x0 is 1 for .1s, x0 and x1 are 0 otherwise</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">Piecewise</span><span class="p">({</span><span class="mi">0</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="mf">0.1</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]}))</span>

    <span class="c1"># Connect the input signal to the neural ensemble</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">neurons</span><span class="p">)</span>

    <span class="c1"># Create the feedback connection using our transform matrix</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">neurons</span><span class="p">,</span> <span class="n">neurons</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="n">tau</span><span class="o">*</span><span class="n">omega</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="n">tau</span><span class="o">*</span><span class="n">omega</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">synapse</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="c1"># You could define a function and use that instead of transform</span>
    <span class="c1">#def recurrent(x):</span>
    <span class="c1">#    return [tau*omega*x[1]+x[0],-tau*omega*x[0]+x[1]]</span>
    <span class="c1">#nengo.Connection(neurons, neurons, function=recurrent, synapse=0.1)</span>
</pre></div>
</div>
</div>
</div>
<p>Probe it, run it, plot it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">input_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;output&quot;</span><span class="p">)</span>
    <span class="n">neuron_probe</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">neurons</span><span class="p">,</span> <span class="s2">&quot;decoded_output&quot;</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Create the simulator</span>
<span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="c1"># Run it for 5 seconds</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">neuron_probe</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (s)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;large&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;$x_0$&quot;</span><span class="p">,</span> <span class="s2">&quot;$x_1$&quot;</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">neuron_probe</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Decoded Output&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x_0$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$x_1$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="id6">
<h3>Discussion<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p>If we look at the changes to <span class="math notranslate nohighlight">\(\dot{x}\)</span>, we can see that <span class="math notranslate nohighlight">\(\dot{x}_0 = \omega x_1\)</span> and <span class="math notranslate nohighlight">\(\dot{x}_1 = -\omega x_0\)</span>
$<span class="math notranslate nohighlight">\(\begin{bmatrix}
    \dot{x}_0 \\
    \dot{x}_1 
\end{bmatrix} = \begin{bmatrix}
		            0 &amp; \omega \\
		            -\omega &amp; 0  
	            \end{bmatrix} \begin{bmatrix}
                                    x_0 \\
                                    x_1 
                                \end{bmatrix}\)</span>$</p>
<p>In both plots, you can see that as <span class="math notranslate nohighlight">\(x_0\)</span> gets more positive, <span class="math notranslate nohighlight">\(x_1\)</span> gets more negative and vice versa. Recall the earlier notes on the synapses for the recurrent neurons. Smaller time constants will cause significant drift. Larger time constants will decrease the drift. <strong>Try it!</strong></p>
<p>We can also adjust the <span class="math notranslate nohighlight">\(\omega\)</span> term to change the frequency of oscillation. We do so by (Nengo) learning new decoder weights! <strong>Try it!</strong></p>
<p>An example for a <a class="reference external" href="https://www.nengo.ai/nengo/examples/dynamics/controlled-oscillator.html">controlled oscillator</a> is available online and is a far more elegant example. The above example does not have an additional input that controls the frequency of the oscillations. Instead, once things are kicked off they keep going at the same frequency until the amplitudes decay back to zero.</p>
</section>
</section>
<section id="resources">
<h2>Resources<a class="headerlink" href="#resources" title="Link to this heading">#</a></h2>
<p>Other dynamics tutorials <a class="reference external" href="https://www.nengo.ai/nengo/examples.html#building-dynamical-systems">can be found here</a>.<br />
Every example we cover in this notebook can be found <a class="reference external" href="https://youtu.be/Fl4cfZCie-w?si=eSyLzeAu2jluMFZ3">in this video</a> if you would like an alternate teaching method to assist in your understanding of the concept.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Tutorial3b_NeuronBasics.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Nengo Neurons: Transformation</p>
      </div>
    </a>
    <a class="right-next"
       href="Tutorial6_PathPlanning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Algorithms in Nengo: Path Planning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#set-up">Set up</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bad-recurrence-using-neurons">Bad Recurrence using Neurons</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrence-in-nengo">Recurrence in Nengo</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#okay-but-why">Okay, but WHY?!</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-feedback">Why feedback?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#let-s-actually-do-that-now">Let’s actually do that now!</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#functions-versus-transforms">Functions versus Transforms</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integrator">Integrator</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#probe-it-and-run-it">Probe it and Run it</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-it">Plot it</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-memory">Working Memory</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Probe it and Run it</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Plot it</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-oscillator-on-your-own-for-an-additional-example">Simple Oscillator - On your own for an additional example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resources">Resources</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Kaitlin Fair
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>