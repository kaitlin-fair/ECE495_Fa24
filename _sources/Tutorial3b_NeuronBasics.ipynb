{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nengo Neurons: Transformation\n",
    "\n",
    "In this demonstration we will:\n",
    "\n",
    "1. Add using a single neuron\n",
    "2. Discuss decoders in more depth\n",
    "3. Perform simple mathematical computations using neurons (such as squaring values)\n",
    "4. Perform mathematical computations that require 2-D neurons (such as multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up\n",
    "\n",
    "**Ensure you are using your [495 Virtual Environment](https://kaitlin-fair.github.io/ECE495_Fa24/venv_setup.html) before you begin!**  \n",
    "    \n",
    "Import Nengo and other supporting libraries into your program to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "import nengo\n",
    "from nengo.utils.matplotlib import rasterplot\n",
    "from nengo.dists import Uniform\n",
    "from nengo.processes import WhiteSignal\n",
    "from nengo.processes import Piecewise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition using neurons\n",
    "\n",
    "Do you think you need multiple neurons to add, or can a single neuron do it alone?\n",
    "\n",
    "Inputs to a neuron ensemble are spike rates. Higher spike rates represent higher values, lower rates for lower values. If the neuron ensemble is recieving all of these spikes and passing along the info, the spike rate out is the combined rate.\n",
    "\n",
    "Think through this: all neurons are firing at 100Hz over 1 second and you're wanting to add a value of .2 (20 spikes) to .3 (30 spikes). That means your adder neuron ensemble receives 50 spikes. What value would that decode to for a firing rate of 100Hz?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the model object\n",
    "model = nengo.Network(label=\"Addition\")\n",
    "with model:\n",
    "    # Create 3 ensembles each containing 100 leaky integrate-and-fire neurons\n",
    "    A = nengo.Ensemble(100, dimensions=1)\n",
    "    B = nengo.Ensemble(100, dimensions=1)\n",
    "    C = nengo.Ensemble(100, dimensions=1)\n",
    "\n",
    "with model:\n",
    "    # Create input nodes representing constant values\n",
    "    input_a = nengo.Node(output=-0.5)\n",
    "    input_b = nengo.Node(output=0.3)\n",
    "\n",
    "    # Connect the input nodes to the appropriate ensembles\n",
    "    nengo.Connection(input_a, A)\n",
    "    nengo.Connection(input_b, B)\n",
    "\n",
    "    # Connect input ensembles A and B to output ensemble C\n",
    "    nengo.Connection(A, C)\n",
    "    nengo.Connection(B, C)\n",
    "\n",
    "with model:\n",
    "    input_a_probe = nengo.Probe(input_a)\n",
    "    input_b_probe = nengo.Probe(input_b)\n",
    "    A_probe = nengo.Probe(A, synapse=0.01)\n",
    "    B_probe = nengo.Probe(B, synapse=0.01)\n",
    "    C_probe = nengo.Probe(C, synapse=0.01)\n",
    "    spikesA = nengo.Probe(A.neurons)\n",
    "    spikesB = nengo.Probe(B.neurons)\n",
    "    spikesC = nengo.Probe(C.neurons)\n",
    "\n",
    "# Create the simulator\n",
    "with nengo.Simulator(model) as sim:\n",
    "    # Run it for 5 seconds\n",
    "    sim.run(1)\n",
    "\n",
    "# Plot the input signals and decoded ensemble values\n",
    "t = sim.trange()\n",
    "plt.figure()\n",
    "plt.plot(sim.trange(), sim.data[A_probe], label=\"Decoded Ensemble A\")\n",
    "plt.plot(sim.trange(), sim.data[B_probe], label=\"Decoded Ensemble B\")\n",
    "plt.plot(sim.trange(), sim.data[C_probe], label=\"Decoded Ensemble C\")\n",
    "plt.plot(\n",
    "    sim.trange(), sim.data[input_a_probe], label=\"Input A\", color=\"k\", linewidth=2.0\n",
    ")\n",
    "plt.plot(\n",
    "    sim.trange(), sim.data[input_b_probe], label=\"Input B\", color=\"0.75\", linewidth=2.0\n",
    ")\n",
    "plt.legend()\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is not intuitive to you, I encourage you to use a single neuron to encode .2 at 100Hz and a single neuron to encode .3 at 100Hz. View your output spikes. Add them together using a third (single) neuron at 100Hz and view the output spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's talk decoders (again)\n",
    "\n",
    "Adding is easy! But what if you want to do something a little more complex - say, $(x+y)^2$? This requires us to dive into decoders once more.\n",
    "\n",
    "Recall (from neuron representation): We multiply our \"filtered spike trains\" with decoding weights and sum them together to give an estimate of the input based on the spikes (i.e. our decoded signal). The decoding weights assign weights to each neuron output based on how important that is to approximating the signal (i.e. more important = higher amplitude/weight when added together). \n",
    "\n",
    "Nengo trains decoding weights - similar to weights of a neural network - that are used to reconstruct the input value via spiking neuron outputs. The decoding weights are determined by minimizing the squared difference between the decoded estimate and the actual input signal. Nengo does this for us and we can get our decoding values from our model. Because weights are trained values between neuron layers, we must get the weights from a connection.\n",
    "\n",
    "There is a really [helpful video](https://youtu.be/JCA2gOhN5oM?si=S0Pj-T4NoHHfEEuO&t=5576) to understand how these decoder weights can be learned in real-time - great for edge computing. The whole video is great, but this link should start the video at 1hr32min and will explain how decoders are learned in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communication Channel\n",
    "\n",
    "To solidify our understanding of decoders, let's connect two neuron ensembles together to represent an input signal:  \n",
    "[Input] ---> (A) ---> (B) ---> [Output]\n",
    "\n",
    "We will then assess the decoders and decide if it makes sense.\n",
    "\n",
    "#### Build your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'model' object to which we can add ensembles, connections, etc.\n",
    "model = nengo.Network(label=\"Communications Channel\")\n",
    "with model:\n",
    "    # Create an abstract input signal that oscillates as sin(t)\n",
    "    sin = nengo.Node(lambda t: np.sin(2*np.pi*t))\n",
    "\n",
    "    # Create an ouput node to view weights from 2nd ensemble\n",
    "    out_node = nengo.Node(size_in=1)\n",
    "\n",
    "    # Create the neuronal ensembles\n",
    "    A = nengo.Ensemble(100, dimensions=1)\n",
    "    B = nengo.Ensemble(100, dimensions=1)\n",
    "\n",
    "    # Connect the input to the first neuronal ensemble\n",
    "    nengo.Connection(sin, A)\n",
    "\n",
    "    # Connect the first neuronal ensemble to the second\n",
    "    # (this is the communication channel)\n",
    "    decoder_connA = nengo.Connection(A, B)\n",
    "\n",
    "    # Connect the second neuronal ensemble to the output node\n",
    "    # (this is where decoders for B are stored)\n",
    "    decoder_connB =nengo.Connection(B, out_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add probes to your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    sin_probe = nengo.Probe(sin)\n",
    "    A_probe = nengo.Probe(A, synapse=0.01)  # ensemble output\n",
    "    B_probe = nengo.Probe(B, synapse=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Input\")\n",
    "plt.plot(sim.trange(), sim.data[sin_probe])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"A\")\n",
    "plt.plot(sim.trange(), sim.data[A_probe])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"B\")\n",
    "plt.plot(sim.trange(), sim.data[B_probe])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Decoders\n",
    "\n",
    "Do you think decoder values for A and B will be the same or different?? Why??\n",
    "\n",
    "Let's check your intuition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probe the weights from the connection between the neuron and output node (out_conn)\n",
    "with nengo.Simulator(model) as sim:\n",
    "    decodersA = sim.data[decoder_connA].weights\n",
    "    decodersB = sim.data[decoder_connB].weights\n",
    "\n",
    "print(\" [  A Decoders   |   B Decoders  ]\")\n",
    "print(np.concatenate((np.transpose(decodersA)[0:20],np.transpose(decodersB)[0:20]), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "Decoder values are computing using least squares, where the decoders minimize the squared difference between the decoded estimate and the actual input signal:\n",
    "\n",
    "$$<<x-\\hat{x}>^2>_x$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\\hat{x} = \\sum{a_i d_i}$$\n",
    "\n",
    "with $x$ being the original input signal, $\\hat{x}$ being the decoded signal, $a_i$  being neuron activities (i.e. firing rates), and $d_i$ being decoder values.\n",
    "\n",
    "Now, given that every neuron in a neuron ensemble has randomly set parameters (unless you hand-choose them), we _should not expect the decoders at ensemble A to be equivalent to those at ensemble B_. Suppose our ensemble A parameters are exactly equivalent to ensemble B, then what? Let's see:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes the tuning curves perfectly spaced out\n",
    "def aligned(n_neurons, radius=0.9):\n",
    "    intercepts = np.linspace(-radius, radius, n_neurons) # even spaced from -.9 to .9\n",
    "    encoders = np.tile([[1], [-1]], (n_neurons // 2, 1)) # half care about negative, half positive\n",
    "    intercepts *= encoders[:, 0]\n",
    "    return intercepts, encoders\n",
    "\n",
    "intercepts, encoders = aligned(100)  # Makes evenly spaced intercepts\n",
    "\n",
    "# Create a 'model' object to which we can add ensembles, connections, etc.\n",
    "model = nengo.Network(label=\"Communications Channel 2\")\n",
    "with model:\n",
    "    # Create an abstract input signal that oscillates as sin(t)\n",
    "    sin = nengo.Node(lambda t: np.sin(2*np.pi*t))\n",
    "\n",
    "    # Create an ouput node to view weights from 2nd ensemble\n",
    "    out_node = nengo.Node(size_in=1)\n",
    "\n",
    "    # Create the neuronal ensembles\n",
    "    A = nengo.Ensemble(100,\n",
    "        dimensions=1,\n",
    "        intercepts=intercepts,\n",
    "        max_rates=Uniform(100, 100), #evenly distributed between 80 and 100Hz\n",
    "        encoders=encoders)\n",
    "    B = nengo.Ensemble(100,\n",
    "        dimensions=1,\n",
    "        intercepts=intercepts,\n",
    "        max_rates=Uniform(100, 100), #evenly distributed between 80 and 100Hz\n",
    "        encoders=encoders)\n",
    "\n",
    "    # Connect the input to the first neuronal ensemble\n",
    "    nengo.Connection(sin, A)\n",
    "\n",
    "    # Connect the first neuronal ensemble to the second\n",
    "    # (this is the communication channel)\n",
    "    decoder_connA = nengo.Connection(A, B)\n",
    "\n",
    "    # Connect the second neuronal ensemble to the output node\n",
    "    # (this is where decoders for B are stored)\n",
    "    decoder_connB =nengo.Connection(B, out_node)\n",
    "\n",
    "    # probe the weights from the connection between the neuron and output node (out_conn)\n",
    "with nengo.Simulator(model) as sim:\n",
    "    decodersA = sim.data[decoder_connA].weights\n",
    "    decodersB = sim.data[decoder_connB].weights\n",
    "\n",
    "print(\" [  A Decoders   |   B Decoders  ]\")\n",
    "print(np.concatenate((np.transpose(decodersA)[0:20],np.transpose(decodersB)[0:20]), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are _the same_! However, notice that the decoded signals are a little noiser. This may be becuase we do not adequately span the space of our signal. With more variety of neuron parameters, we can better capture the complexity of the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple computations using neurons and their decoders\n",
    "\n",
    "So, why did we hit decoders _again_?? \n",
    "\n",
    "Encoding and decoding allow us to encode signals over time, and decode transformations of those signals. So far, we've only decoded the signal itself (i.e. a boring but necessary to understand transformation).\n",
    "\n",
    "Now, we will decode arbitrary transformations of the input signal. These arbitrary transformations are functions performed on our neuron activities (i.e. outputs of the neuron ensembles that encode the input signal). These functions are computed by _learning decoder weights that perform the computation_. This means that if we want to square an input signal, the decoder weights will be learned such that when the filtered neuron spikes are weighted and added up, they'll result in the squared value.\n",
    "\n",
    "If equations are helpful to you, we now have an output that is $f(x)=x^2$. Nengo learns the encoders in the same way as before, except it's now minimizing the difference between the decoded estimate of $\\hat{f}(x)=\\hat{x}^2$ and the actual computed value $f(x)=x^2$, where $\\hat{x}$ is the encoded input signal and $x$ is the actual input signal:   \n",
    "\n",
    "$$<<f(x)-\\hat{f}(x)>^2>_{x}$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\\hat{f}(x) = \\sum{a_i d_i}$$\n",
    "\n",
    "Note: these decoders are learned such that it can handle time-varying input so long as the values used fall within the neuron's radius! This means that regardless of input values, these decoder weights should be used able to effectively decode the function outputs. If it's innacurate, you might just need more neurons.\n",
    "\n",
    "Enough about that, let’s decode the square of a white noise input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model object\n",
    "model = nengo.Network(label=\"Squaring\")\n",
    "with model:\n",
    "    input = nengo.Node(WhiteSignal(1, high=5), size_out=1)\n",
    "    A = nengo.Ensemble(30, dimensions=1, max_rates=Uniform(80, 100))\n",
    "\n",
    "    # connect the input to the neuron ensemble\n",
    "    nengo.Connection(input, A)\n",
    "\n",
    "    # probe input node and neuron ensemble\n",
    "    input_probe = nengo.Probe(input)\n",
    "    A_spikes = nengo.Probe(A.neurons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key here is that we now define a function to be used at a connection. This is how we will square our white noise input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "\n",
    "# Define functions\n",
    "\n",
    "    def square(x):\n",
    "        return x*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our connection between our neuron ensemble (encoding the input) and our output node (the final answer) contains the decoders that compute $x^2$. This is completed by adding an argument called `function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    # add an output node\n",
    "    Asquare = nengo.Node(size_in=1)\n",
    "    \n",
    "    # connect the neuron ensemble to the output node with a function\n",
    "    nengo.Connection(A, Asquare, function=square)\n",
    "\n",
    "    # probe the output to assess results\n",
    "    Asquare_probe = nengo.Probe(Asquare, synapse=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 3.5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(sim.trange(), sim.data[input_probe], label=\"Input signal\")\n",
    "plt.plot(sim.trange(), sim.data[Asquare_probe], label=\"Decoded estimate\")\n",
    "plt.plot(sim.trange(), np.square(sim.data[input_probe]), label=\"Input signal squared\")\n",
    "plt.legend(loc=\"best\", fontsize=\"medium\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "rasterplot(sim.trange(), sim.data[A_spikes])\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Neuron\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check our intuition on decoders once more\n",
    "\n",
    "I know... hang with me though...\n",
    "\n",
    "We will add an additional output probe that connects the same ensemble to an output that is just passing data. This means there will be no function associated with the connection, but there will still be trained/learned decoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    # add an output node\n",
    "    Aoutput = nengo.Node(size_in=1)\n",
    "    \n",
    "    # connect the neuron ensemble to the output node WITHOUT a function\n",
    "    nengo.Connection(A, Aoutput)\n",
    "\n",
    "    # probe the output to assess results\n",
    "    Aout_probe = nengo.Probe(Aoutput, synapse=0.01)\n",
    "\n",
    "\n",
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 3.5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(sim.trange(), sim.data[input_probe], label=\"Input signal\")\n",
    "plt.plot(sim.trange(), sim.data[Asquare_probe], label=\"Decoded estimate\")\n",
    "plt.plot(sim.trange(), np.square(sim.data[input_probe]), label=\"Input signal squared\")\n",
    "plt.legend(loc=\"best\", fontsize=\"medium\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "rasterplot(sim.trange(), sim.data[A_spikes])\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Neuron\")\n",
    "\n",
    "plt.figure(figsize=(10, 3.5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(sim.trange(), sim.data[input_probe], label=\"Input signal\")\n",
    "plt.plot(sim.trange(), sim.data[Aout_probe], label=\"Decoded estimate\")\n",
    "plt.legend(loc=\"best\", fontsize=\"medium\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.xlim(0, 1)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "rasterplot(sim.trange(), sim.data[A_spikes])\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Neuron\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the spike trains are exactly the same!! The only difference is how we’re interpreting those spikes. We told Nengo to compute two sets of decoders, one that estimates the function $x^2$ and one that estimates the input signal.\n",
    "\n",
    "In general, the transformation principle determines how we can decode spike trains to compute linear and nonlinear transformations of signals encoded in a population of neurons. We can then project those transformed signals into another population, and repeat the process. This means we can use the same neuron ensemble output and do many different things to it in parallel by connecting it to different nodes / ensembles with different weights. This will come in quite handy when we start mapping algorithms to neurons.\n",
    "\n",
    "**Your turn! Try changing your function and see how well it works.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computations with 2-dimensional neurons\n",
    "\n",
    "You may have noticed that you can only generate functions using the above model if it involves a single input. Recall addition - we had 2 inputs but we didn't need any distinction between the two. What if instead you wanted to compute $x^2+y$? We can do $x^2$ using the above model, but how do we ensure we square only the input $x$ and not $y$?? \n",
    "\n",
    "2D neurons can keep the two values separate as they enter the ensemble. One dimension is used for the first input $x$, the other for the second input $y$. Then, you can learn decoders for a function $f(x,y)=x^2+y$ between the 2D ensemble and whatever is next.\n",
    "\n",
    "We will do multiplication of a piecewise function to show how this works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model object\n",
    "model = nengo.Network(label=\"Multiplication\")\n",
    "with model:\n",
    "\n",
    "    # Create a piecewise step function for input\n",
    "    inputA = nengo.Node(Piecewise({0: 0, 2.5: 1, 4: -1}))\n",
    "    inputB = nengo.Node(Piecewise({0: 1, 1.5: .2, 3: 0, 4.5: .2}))\n",
    "\n",
    "    correct_ans = Piecewise({0: 0, 1.5: 0, 2.5: .2, 3: 0, 4: 0, 4.5: -.2})\n",
    "\n",
    "    # Create 4 ensembles of leaky integrate-and-fire neurons\n",
    "    A = nengo.Ensemble(100, dimensions=1)\n",
    "    B = nengo.Ensemble(100, dimensions=1)\n",
    "    combined = nengo.Ensemble(220, dimensions=2)  \n",
    "    prod = nengo.Ensemble(100, dimensions=1)\n",
    "\n",
    "    # Connect the input nodes to the appropriate ensembles\n",
    "    nengo.Connection(inputA, A)\n",
    "    nengo.Connection(inputB, B)\n",
    "\n",
    "    # Connect input ensembles A and B to the 2D combined ensemble\n",
    "    nengo.Connection(A, combined[0])\n",
    "    nengo.Connection(B, combined[1])\n",
    "\n",
    "    # Define a function that computes the multiplication of two inputs\n",
    "    def product(x):\n",
    "        return x[0] * x[1]\n",
    "\n",
    "    # Connect the combined ensemble to the output ensemble D\n",
    "    nengo.Connection(combined, prod, function=product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probe all the things and run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    inputA_probe = nengo.Probe(inputA)\n",
    "    inputB_probe = nengo.Probe(inputB)\n",
    "    A_probe = nengo.Probe(A, synapse=0.01)\n",
    "    B_probe = nengo.Probe(B, synapse=0.01)\n",
    "    combined_probe = nengo.Probe(combined, synapse=0.01)\n",
    "    prod_probe = nengo.Probe(prod, synapse=0.01)\n",
    "\n",
    "# Create the simulator\n",
    "with nengo.Simulator(model) as sim:\n",
    "    # Run it for 5 seconds\n",
    "    sim.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the input signals and decoded ensemble values\n",
    "plt.figure()\n",
    "plt.plot(sim.trange(), sim.data[A_probe], label=\"Decoded A\")\n",
    "plt.plot(sim.trange(), sim.data[B_probe], label=\"Decoded B\")\n",
    "plt.plot(sim.trange(), sim.data[prod_probe], label=\"Decoded product\")\n",
    "plt.plot(\n",
    "    sim.trange(), correct_ans.run(sim.time, dt=sim.dt), c=\"k\", label=\"Actual product\"\n",
    ")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(-1.1, 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to use values greater than 1?? Let's take a look at our Nengo GUI!\n",
    "\n",
    "In your terminal, type `nengo`. This will launch a web browser with (hopefully) a ready to go default simulation file. We are going to take a look at what happens when we start working with values greater than 1 and how to deal with 2-D neurons as their values also increase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computations with 2-dimensional neurons, again\n",
    "\n",
    "Here, we repeat our multiplication, but with values greater than 1.\n",
    "\n",
    "Note the radii defined for each neuron ensemble. For the 1D neurons, you set the radius to your known max value, $10$. For the 2D neuron, you need to think of your possible values as a \"unit square\", resulting in the max value of the 2D neuron ($\\sqrt{10}+\\sqrt{10}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model object\n",
    "model = nengo.Network(label=\"Multiplication 2\")\n",
    "with model:\n",
    "\n",
    "    # Create a piecewise step function for input\n",
    "    inputA = nengo.Node(Piecewise({0: 0, 2.5: 10, 4: -10}))\n",
    "    inputB = nengo.Node(Piecewise({0: 10, 1.5: 2, 3: 0, 4.5: 2}))\n",
    "\n",
    "    correct_ans = Piecewise({0: 0, 1.5: 0, 2.5: 20, 3: 0, 4: 0, 4.5: -20})\n",
    "\n",
    "    # Create 4 ensembles of leaky integrate-and-fire neurons\n",
    "    A = nengo.Ensemble(100, dimensions=1, radius=10)\n",
    "    B = nengo.Ensemble(100, dimensions=1, radius=10)\n",
    "    combined = nengo.Ensemble(\n",
    "        220, dimensions=2, radius=15\n",
    "    )  # This radius is ~sqrt(10^2+10^2)\n",
    "    prod = nengo.Ensemble(100, dimensions=1, radius=20)\n",
    "\n",
    "    # Connect the input nodes to the appropriate ensembles\n",
    "    nengo.Connection(inputA, A)\n",
    "    nengo.Connection(inputB, B)\n",
    "\n",
    "    # Connect input ensembles A and B to the 2D combined ensemble\n",
    "    nengo.Connection(A, combined[0])\n",
    "    nengo.Connection(B, combined[1])\n",
    "\n",
    "    # Define a function that computes the multiplication of two inputs\n",
    "    def product(x):\n",
    "        return x[0] * x[1]\n",
    "\n",
    "    # Connect the combined ensemble to the output ensemble D\n",
    "    nengo.Connection(combined, prod, function=product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probe all the things and run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    inputA_probe = nengo.Probe(inputA)\n",
    "    inputB_probe = nengo.Probe(inputB)\n",
    "    A_probe = nengo.Probe(A, synapse=0.01)\n",
    "    B_probe = nengo.Probe(B, synapse=0.01)\n",
    "    combined_probe = nengo.Probe(combined, synapse=0.01)\n",
    "    prod_probe = nengo.Probe(prod, synapse=0.01)\n",
    "\n",
    "# Create the simulator\n",
    "with nengo.Simulator(model) as sim:\n",
    "    # Run it for 5 seconds\n",
    "    sim.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the input signals and decoded ensemble values\n",
    "plt.figure()\n",
    "plt.plot(sim.trange(), sim.data[A_probe], label=\"Decoded A\")\n",
    "plt.plot(sim.trange(), sim.data[B_probe], label=\"Decoded B\")\n",
    "plt.plot(sim.trange(), sim.data[prod_probe], label=\"Decoded product\")\n",
    "plt.plot(\n",
    "    sim.trange(), correct_ans.run(sim.time, dt=sim.dt), c=\"k\", label=\"Actual product\"\n",
    ")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(-25, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Turn\n",
    "\n",
    "Using everything we've learned, implement the function $f(x,y)=x^2+y$ using neurons. If you choose to use values greater than 1, choose your neuron radii accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10-nengo3.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
